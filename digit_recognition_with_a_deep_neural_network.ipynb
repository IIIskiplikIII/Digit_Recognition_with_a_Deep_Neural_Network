{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np # linear algebra\r\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "#import seaborn as sn\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from random import seed\r\n",
    "seed(1)\r\n",
    "\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "print(\"Tensorflow Version: \", tf.__version__)\r\n",
    "print(\"Keras Version: \",keras.__version__)\r\n",
    "\r\n",
    "\r\n",
    "kaggle = 0 # Kaggle path active = 1\r\n",
    "\r\n",
    "# change your local path here\r\n",
    "if kaggle == 1 :\r\n",
    "    MNIST_PATH= '../input/digit-recognizer'\r\n",
    "else:\r\n",
    "    MNIST_PATH= '../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer'\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "import os\r\n",
    "for dirname, _, filenames in os.walk(MNIST_PATH): \r\n",
    "    for filename in filenames:\r\n",
    "        print(os.path.join(dirname, filename))\r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow Version:  2.3.0\n",
      "Keras Version:  2.4.0\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\sample_submission.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\test.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\train.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction - MNIST Training Competition\r\n",
    "Link to the topic: https://www.kaggle.com/c/digit-recognizer/data\r\n",
    "\r\n",
    "This is another Notebook to take a look into annother algorithm. Here I want to give the Deep Neural Network with the Framework Keras a try. As already mentioned in other notebooks, I will skip some explanations about the data set here. Moreover I will use the already discovered knowledge about the data and transform/prepare the data rightaway.\r\n",
    "\r\n",
    "If you are interested in some more clearly analysis of the dataset take a look into my other notebooks about the MNIS-dataset:\r\n",
    "- Another MNIST Try: https://www.kaggle.com/skiplik/another-mnist-try\r\n",
    "- First NN by Detecting Handwritten Characters: https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters\r\n",
    "...\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Data path and file\r\n",
    "#MNIST_PATH= '../input/digit-recognizer'\r\n",
    "#MNIST_PATH= '../Another_MNIST_try/data/input/digit-recognizer'\r\n",
    "CSV_FILE_TRAIN='train.csv'\r\n",
    "CSV_FILE_TEST='test.csv'\r\n",
    "\r\n",
    "def load_mnist_data(minist_path, csv_file):\r\n",
    "    csv_path = os.path.join(minist_path, csv_file)\r\n",
    "    return pd.read_csv(csv_path)\r\n",
    "\r\n",
    "def load_mnist_data_manuel(minist_path, csv_file):\r\n",
    "    csv_path = os.path.join(minist_path, csv_file)\r\n",
    "    csv_file = open(csv_path, 'r')\r\n",
    "    csv_data = csv_file.readlines()\r\n",
    "    csv_file.close()\r\n",
    "    return csv_data\r\n",
    "\r\n",
    "def split_train_val(data, val_ratio):\r\n",
    "    return \r\n",
    "    \r\n",
    "\r\n",
    "train = load_mnist_data(MNIST_PATH,CSV_FILE_TRAIN)\r\n",
    "test = load_mnist_data(MNIST_PATH,CSV_FILE_TEST)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "y = train['label'].copy()\r\n",
    "X = train.drop(['label'], axis=1)\r\n",
    "\r\n",
    "X_test = test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train / Val Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(\"Shape of the Features: \",X.shape)\r\n",
    "print(\"Shape of the Labels: \", y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the Features:  (42000, 784)\n",
      "Shape of the Labels:  (42000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TK - Label Value Count\r\n",
    "Visualizing the label distribution of the full train dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train.value_counts('label')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=43, test_size=0.25, stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing the equally splitted train- and val-sets based on the given label y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(\"Train - Set Distribution\")\r\n",
    "print(y_train.value_counts() / y_train.value_counts().sum() )\r\n",
    "print('--------------------------------------------------------------')\r\n",
    "print('--------------------------------------------------------------')\r\n",
    "print('--------------------------------------------------------------')\r\n",
    "print(\"Val - Set Distribution\")\r\n",
    "print(y_val.value_counts() / y_val.value_counts().sum() )\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train - Set Distribution\n",
      "1    0.111524\n",
      "7    0.104794\n",
      "3    0.103587\n",
      "9    0.099714\n",
      "2    0.099460\n",
      "6    0.098508\n",
      "0    0.098381\n",
      "4    0.096952\n",
      "8    0.096730\n",
      "5    0.090349\n",
      "Name: label, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Val - Set Distribution\n",
      "1    0.111524\n",
      "7    0.104762\n",
      "3    0.103619\n",
      "9    0.099714\n",
      "2    0.099429\n",
      "6    0.098476\n",
      "0    0.098381\n",
      "4    0.096952\n",
      "8    0.096762\n",
      "5    0.090381\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"X: \", X.shape)\r\n",
    "print(\"X_train: \", X_train.shape)\r\n",
    "print(\"X_val: \", X_val.shape)\r\n",
    "\r\n",
    "print(\"y_train: \", y_train.shape)\r\n",
    "print(\"y_val: \", y_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X:  (42000, 784)\n",
      "X_train:  (31500, 784)\n",
      "X_val:  (10500, 784)\n",
      "y_train:  (31500,)\n",
      "y_val:  (10500,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Transforming Piplines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import Normalizer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "pipeline = Pipeline([\r\n",
    "    ('normalizer', Normalizer())\r\n",
    "    #('std_scalar',StandardScaler())\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_train_prep = pipeline.fit_transform(X_train)      # fitting the pipeline to the train and transform it\r\n",
    "X_val_prep = pipeline.transform(X_val)              # transform val data with this information"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Deep Neural Network based on RandomizedSearch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Model Visualization with Tensorboard (not for Kaggle)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "root_logdir = \"../../tensorboard-logs\"\r\n",
    "\r\n",
    "print(\"Relative root_logdir: \",root_logdir)\r\n",
    "\r\n",
    "def get_run_logdir():\r\n",
    "    import time\r\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\r\n",
    "    return os.path.join(root_logdir,run_id)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relative root_logdir:  ../../tensorboard-logs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "run_logdir = get_run_logdir()\r\n",
    "print(\"Current run logdir for Tensorboard: \", run_logdir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current run logdir for Tensorboard:  ../../tensorboard-logs\\run_2021_08_20-08_42_51\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "run_logdir"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../tensorboard-logs\\\\run_2021_08_20-08_42_51'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keras Callbacks for Tensorboard\r\n",
    "With Keras there is a way of using Callbacks for the Tensorboard to write log files for the board and visualize the different graphs (loss and val curve)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Architecture for Hyperparameter Optimization\r\n",
    "- Amount of Layers\r\n",
    "- Amount of Neurons\r\n",
    "- Learningrate\r\n",
    "- Checkpoints !!!!!!!!!!!!!!!!!!!!!\r\n",
    "- Early Stopping "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[784]):\r\n",
    "    model = keras.models.Sequential()                               # base model structure (Sequential API by Keras)\r\n",
    "\r\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))     # input layer\r\n",
    "\r\n",
    "    for layer in range(n_hidden):                                   # add layers as often as defined in constructor \r\n",
    "        model.add(keras.layers.Dense(n_neurons,activation=\"relu\"))  # add layer with given neurons and relu activation function\r\n",
    "\r\n",
    "    model.add(keras.layers.Dense(10))                               # add output layer \r\n",
    "\r\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)   # define optimizer (especially the larning rate for hyperparameter optimization)\r\n",
    "\r\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)                  # make it ready\r\n",
    "\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Using keras wrapper as hull \r\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from scipy.stats import reciprocal\r\n",
    "\r\n",
    "# Hyperparameter set\r\n",
    "param_dist= {\r\n",
    "            \"n_neurons\": range(20, 300, 20)\r\n",
    "            ,\"n_hidden\": range(10, 150, 10)\r\n",
    "            ,\"learning_rate\": [1e-3, 2e-3, 3e-3]\r\n",
    "    }\r\n",
    "\r\n",
    "param_dist_right = {\r\n",
    "        \"n_neurons\": [150]\r\n",
    "        ,\"n_hidden\": [30]\r\n",
    "        ,\"learning_rate\": [2e-3]  \r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TK - Model Checkpoints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "### will be implemented"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Randomized Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Finding best hyperparameters with Randomized search\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "\r\n",
    "ran_ker_reg = RandomizedSearchCV(keras_reg, param_dist, n_iter=5, cv=3, random_state=42, return_train_score=True)\r\n",
    "history_ker_reg = ran_ker_reg.fit(X_train_prep, y_train, epochs=100, validation_data=(X_val_prep, y_val), callbacks=[keras.callbacks.EarlyStopping(patience=10), tensorboard_cb])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "  1/657 [..............................] - ETA: 0s - loss: 29.2500WARNING:tensorflow:From D:\\anaconda3\\envs\\wingpuflake_keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.0425s). Check your callbacks.\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 15.8303 - val_loss: 8.3547\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3384 - val_loss: 8.3401\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3331 - val_loss: 8.3443\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3351 - val_loss: 8.3609\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3328 - val_loss: 8.3610\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3346 - val_loss: 8.3958\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3372 - val_loss: 8.3740\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3333 - val_loss: 8.3734\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3336 - val_loss: 8.3418\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3335 - val_loss: 8.3575\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3363 - val_loss: 8.3604\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3361 - val_loss: 8.3398\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3344 - val_loss: 8.3706\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 8.3346 - val_loss: 8.3932\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3316 - val_loss: 8.3425\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3355 - val_loss: 8.3883\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 8.3327 - val_loss: 8.3391\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3336 - val_loss: 8.3464\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3323 - val_loss: 8.3389\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3326 - val_loss: 8.3485\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3323 - val_loss: 8.3573\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3348 - val_loss: 8.3662\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3351 - val_loss: 8.3389\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3349 - val_loss: 8.3506\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3303 - val_loss: 8.3412\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3307 - val_loss: 8.3397\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3345 - val_loss: 8.3520\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3291 - val_loss: 8.3389\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3301 - val_loss: 8.3981\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.4275\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3834\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 10:25 - loss: 25.2745WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 1.9035s). Check your callbacks.\n",
      "657/657 [==============================] - 6s 9ms/step - loss: 15.2734 - val_loss: 8.3830\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3559 - val_loss: 8.3608\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3573 - val_loss: 8.3746\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3563 - val_loss: 8.3775\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3562 - val_loss: 8.3859\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3579 - val_loss: 8.3412\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3543 - val_loss: 8.3531\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3600 - val_loss: 8.3424\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3582 - val_loss: 8.3544\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3569 - val_loss: 8.3561\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3511 - val_loss: 8.3569\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3572 - val_loss: 8.3463\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3552 - val_loss: 8.3388\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3546 - val_loss: 8.3457\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3532 - val_loss: 8.3482\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3557 - val_loss: 8.3723\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3542 - val_loss: 8.3395\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3583 - val_loss: 8.3403\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3569 - val_loss: 8.3466\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3509 - val_loss: 8.3633\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3523 - val_loss: 8.3560\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3536 - val_loss: 8.3988\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3557 - val_loss: 8.3541\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.3359\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3633\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 9:33 - loss: 31.8207WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 1.7445s). Check your callbacks.\n",
      "657/657 [==============================] - 6s 9ms/step - loss: 15.6550 - val_loss: 8.3526\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3672 - val_loss: 8.3904\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 8.3657 - val_loss: 8.3409\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3635 - val_loss: 8.3440\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3612 - val_loss: 8.4259\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3658 - val_loss: 8.3396\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3648 - val_loss: 8.3561\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3633 - val_loss: 8.3598\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3632 - val_loss: 8.3814\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3620 - val_loss: 8.3854\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3610 - val_loss: 8.3389\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3644 - val_loss: 8.3566\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3609 - val_loss: 8.3396\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3615 - val_loss: 8.3507\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3646 - val_loss: 8.3441\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3608 - val_loss: 8.3546\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3651 - val_loss: 8.3404\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3637 - val_loss: 8.3485\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3622 - val_loss: 8.3399\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3643 - val_loss: 8.3857\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3625 - val_loss: 8.3388\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3586 - val_loss: 8.3470\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3609 - val_loss: 8.4289\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3633 - val_loss: 8.3397\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3634 - val_loss: 8.3864\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3667 - val_loss: 8.3593\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3604 - val_loss: 8.4243\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3606 - val_loss: 8.3517\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3653 - val_loss: 8.3424\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3613 - val_loss: 8.3585\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 8.3593 - val_loss: 8.3753\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.3510\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3874\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 7:04 - loss: 19.7011WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 1.2940s). Check your callbacks.\n",
      "657/657 [==============================] - 2s 4ms/step - loss: 10.4225 - val_loss: 8.3902\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3484 - val_loss: 8.3416\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3571 - val_loss: 8.3797\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3475 - val_loss: 8.3519\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3523 - val_loss: 8.3401\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3469 - val_loss: 8.3636\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3448 - val_loss: 8.4491\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3410 - val_loss: 8.3691\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3455 - val_loss: 8.3388\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3468 - val_loss: 8.3573\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3464 - val_loss: 8.3615\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3456 - val_loss: 8.3451\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3398 - val_loss: 8.4565\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3427 - val_loss: 8.3650\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3432 - val_loss: 8.3388\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3433 - val_loss: 8.3398\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3383 - val_loss: 8.3799\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3421 - val_loss: 8.3389\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3396 - val_loss: 8.3714\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3418 - val_loss: 8.3824\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3368 - val_loss: 8.6100\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3441 - val_loss: 8.3511\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3395 - val_loss: 8.3930\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3359 - val_loss: 8.3403\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3389 - val_loss: 8.3541\n",
      "329/329 [==============================] - 0s 590us/step - loss: 8.3878\n",
      "657/657 [==============================] - 0s 585us/step - loss: 8.3373\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 4:56 - loss: 22.6743WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.9045s). Check your callbacks.\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 10.8692 - val_loss: 8.5730\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3828 - val_loss: 8.3421\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3686 - val_loss: 8.3412\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3699 - val_loss: 8.3396\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3769 - val_loss: 8.4068\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3791 - val_loss: 8.4961\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3737 - val_loss: 8.3532\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3751 - val_loss: 8.3952\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3668 - val_loss: 8.3745\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3661 - val_loss: 8.3385\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3712 - val_loss: 8.5119\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3702 - val_loss: 8.3392\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3646 - val_loss: 8.4157\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3660 - val_loss: 8.3388\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3661 - val_loss: 8.3778\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3610 - val_loss: 8.4165\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3668 - val_loss: 8.3390\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3673 - val_loss: 8.3450\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3636 - val_loss: 8.3430\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3642 - val_loss: 8.3389\n",
      "329/329 [==============================] - 0s 584us/step - loss: 8.3248\n",
      "657/657 [==============================] - 0s 588us/step - loss: 8.3459\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 4:57 - loss: 33.9624WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.9070s). Check your callbacks.\n",
      "657/657 [==============================] - 2s 3ms/step - loss: 11.2296 - val_loss: 8.4341\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3717 - val_loss: 8.3547\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3723 - val_loss: 8.3450\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3703 - val_loss: 8.3460\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3705 - val_loss: 8.4364\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3725 - val_loss: 8.3390\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3731 - val_loss: 8.3674\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3690 - val_loss: 8.3671\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3701 - val_loss: 8.3731\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3722 - val_loss: 8.3928\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3736 - val_loss: 8.3571\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3664 - val_loss: 8.3546\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3689 - val_loss: 8.3408\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3683 - val_loss: 8.3788\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3666 - val_loss: 8.3359\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3645 - val_loss: 8.4814\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3755 - val_loss: 8.3664\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3634 - val_loss: 8.5438\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3658 - val_loss: 8.3388\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3678 - val_loss: 8.3502\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3657 - val_loss: 8.3443\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3680 - val_loss: 8.3573\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3723 - val_loss: 8.3414\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3618 - val_loss: 8.3657\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3670 - val_loss: 8.4398\n",
      "329/329 [==============================] - 0s 584us/step - loss: 8.4155\n",
      "657/657 [==============================] - 0s 573us/step - loss: 8.4519\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 7:03 - loss: 25.5982WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 1.2885s). Check your callbacks.\n",
      "657/657 [==============================] - 4s 7ms/step - loss: 12.4749 - val_loss: 8.3881\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3419 - val_loss: 8.4757\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3410 - val_loss: 8.3610\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3322 - val_loss: 8.3461\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3376 - val_loss: 8.3426\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3353 - val_loss: 8.3972\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3365 - val_loss: 8.3480\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3377 - val_loss: 8.3631\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3382 - val_loss: 8.3669\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3355 - val_loss: 8.6060\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3363 - val_loss: 8.3752\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3350 - val_loss: 8.3459\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3328 - val_loss: 8.3732\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3313 - val_loss: 8.3997\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3342 - val_loss: 8.3574\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.4004\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3359\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 6:52 - loss: 26.5812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 1.2550s). Check your callbacks.\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 11.7033 - val_loss: 8.4818\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3779 - val_loss: 8.4711\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3749 - val_loss: 8.4343\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3710 - val_loss: 8.3685\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3740 - val_loss: 8.3399\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3689 - val_loss: 8.3600\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3776 - val_loss: 8.3521\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3714 - val_loss: 8.4293\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3681 - val_loss: 8.4023\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3647 - val_loss: 8.3476\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3642 - val_loss: 8.3393\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3700 - val_loss: 8.3406\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3658 - val_loss: 8.3585\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3706 - val_loss: 8.3625\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3688 - val_loss: 8.3955\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3690 - val_loss: 8.3587\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3669 - val_loss: 8.3537\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3614 - val_loss: 8.3449\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3633 - val_loss: 8.3667\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3675 - val_loss: 8.3416\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3643 - val_loss: 8.3392\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3642 - val_loss: 8.3421\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3629 - val_loss: 8.3515\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3643 - val_loss: 8.3403\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3677 - val_loss: 8.3405\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3649 - val_loss: 8.5506\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3602 - val_loss: 8.3676\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3649 - val_loss: 8.3521\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3599 - val_loss: 8.3403\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3618 - val_loss: 8.3446\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3613 - val_loss: 8.3436\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.3323\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3492\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 7:38 - loss: 25.5810WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 1.3950s). Check your callbacks.\n",
      "657/657 [==============================] - 5s 7ms/step - loss: 11.5842 - val_loss: 8.3473\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3776 - val_loss: 8.5570\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3763 - val_loss: 8.3513\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3748 - val_loss: 8.3925\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3752 - val_loss: 8.3400\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3777 - val_loss: 8.4046\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3710 - val_loss: 8.3388\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3754 - val_loss: 8.3452\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3785 - val_loss: 8.3554\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3729 - val_loss: 8.3618\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3733 - val_loss: 8.4315\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3700 - val_loss: 8.3893\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3719 - val_loss: 8.3504\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3687 - val_loss: 8.4316\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3728 - val_loss: 8.3392\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3723 - val_loss: 8.3410\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3682 - val_loss: 8.3676\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 8.3433\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 8.3797\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 9:36 - loss: 27.3058WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 1.7485s). Check your callbacks.\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 14.4038 - val_loss: 8.3399\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3348 - val_loss: 8.4574\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3377 - val_loss: 8.3932\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3328 - val_loss: 8.3407\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3340 - val_loss: 8.3388\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3341 - val_loss: 8.3427\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3404 - val_loss: 8.3405\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3355 - val_loss: 8.3422\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3384 - val_loss: 8.3768\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3365 - val_loss: 8.3471\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3337 - val_loss: 8.3468\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3363 - val_loss: 8.3389\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3316 - val_loss: 8.3450\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3387 - val_loss: 8.3564\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3320 - val_loss: 8.3484\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8.3830\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3311\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 11:04 - loss: 28.2741WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 2.0170s). Check your callbacks.\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 15.3329 - val_loss: 8.3603\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3662 - val_loss: 8.3418\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3603 - val_loss: 8.3398\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3584 - val_loss: 8.3862\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3591 - val_loss: 8.3584\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3607 - val_loss: 8.3389\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3586 - val_loss: 8.3509\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3639 - val_loss: 8.3398\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3668 - val_loss: 8.3391\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3503 - val_loss: 8.3428\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3606 - val_loss: 8.3736\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3676 - val_loss: 8.3476\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3583 - val_loss: 8.3391\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3633 - val_loss: 8.3389\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3548 - val_loss: 8.3529\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3659 - val_loss: 8.3573\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8.3386\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3666\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 10:09 - loss: 23.6665WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 1.8485s). Check your callbacks.\n",
      "657/657 [==============================] - 12s 18ms/step - loss: 15.5174 - val_loss: 8.3505\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3609 - val_loss: 8.3959\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3634 - val_loss: 8.3627\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3647 - val_loss: 8.3686\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3648 - val_loss: 8.3482\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3578 - val_loss: 8.3518\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3625 - val_loss: 8.3551\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3650 - val_loss: 8.3431\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3614 - val_loss: 8.3508\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3634 - val_loss: 8.3390\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3581 - val_loss: 8.3421\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3671 - val_loss: 8.3395\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3625 - val_loss: 8.3394\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 8.3682 - val_loss: 8.3560\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3646 - val_loss: 8.3574\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 9s 13ms/step - loss: 8.3634 - val_loss: 8.3388\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3634 - val_loss: 8.3499\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3636 - val_loss: 8.3462\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3651 - val_loss: 8.3752\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3658 - val_loss: 8.3407\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3637 - val_loss: 8.4005\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3617 - val_loss: 8.3414\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3634 - val_loss: 8.3402\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3595 - val_loss: 8.3863\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3633 - val_loss: 8.3394\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 9s 14ms/step - loss: 8.3611 - val_loss: 8.3388\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8.3145\n",
      "657/657 [==============================] - 3s 4ms/step - loss: 8.3510\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 8:49 - loss: 24.3843WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.6150s). Check your callbacks.\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 14.1804 - val_loss: 8.3574\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3322 - val_loss: 8.3396\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3343 - val_loss: 8.3389\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3319 - val_loss: 8.3595\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3307 - val_loss: 8.3415\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3295 - val_loss: 8.3628\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3304 - val_loss: 8.3392\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3327 - val_loss: 8.4114\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3296 - val_loss: 8.3550\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3334 - val_loss: 8.3396\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3289 - val_loss: 8.3573\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3314 - val_loss: 8.3389\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3321 - val_loss: 8.3406\n",
      "329/329 [==============================] - 0s 673us/step - loss: 8.3802\n",
      "657/657 [==============================] - 0s 685us/step - loss: 8.3208\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 7:56 - loss: 30.9298WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.4530s). Check your callbacks.\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 15.2171 - val_loss: 8.3393\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3632 - val_loss: 8.3388\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3588 - val_loss: 8.3409\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3614 - val_loss: 8.3432\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3617 - val_loss: 8.4493\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3635 - val_loss: 8.3401\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3628 - val_loss: 8.3842\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3594 - val_loss: 8.4282\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3646 - val_loss: 8.3392\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3599 - val_loss: 8.4212\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3599 - val_loss: 8.3806\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3619 - val_loss: 8.3433\n",
      "329/329 [==============================] - 0s 717us/step - loss: 8.3271\n",
      "657/657 [==============================] - 0s 697us/step - loss: 8.3514\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 7:51 - loss: 20.0718WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 1.4375s). Check your callbacks.\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 13.6637 - val_loss: 8.3748\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3597 - val_loss: 8.4407\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3628 - val_loss: 8.3402\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3624 - val_loss: 8.3866\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3643 - val_loss: 8.3455\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3679 - val_loss: 8.3393\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3633 - val_loss: 8.3724\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3591 - val_loss: 8.3423\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3633 - val_loss: 8.3492\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3660 - val_loss: 8.3445\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3630 - val_loss: 8.3528\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3587 - val_loss: 8.3409\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3643 - val_loss: 8.3391\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3623 - val_loss: 8.3387\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3604 - val_loss: 8.3672\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3641 - val_loss: 8.3389\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3611 - val_loss: 8.3573\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3594 - val_loss: 8.3677\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3610 - val_loss: 8.3389\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3619 - val_loss: 8.4498\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3639 - val_loss: 8.5478\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3627 - val_loss: 8.3418\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3662 - val_loss: 8.3614\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 8.3621 - val_loss: 8.3466\n",
      "329/329 [==============================] - 0s 704us/step - loss: 8.3222\n",
      "657/657 [==============================] - 0s 722us/step - loss: 8.3588\n",
      "Epoch 1/100\n",
      "  2/985 [..............................] - ETA: 12:01 - loss: 31.7756WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.4665s). Check your callbacks.\n",
      "985/985 [==============================] - 3s 4ms/step - loss: 16.3961 - val_loss: 8.3545\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3482 - val_loss: 8.3811\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3467 - val_loss: 8.3440\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3451 - val_loss: 8.3544\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3479 - val_loss: 8.3424\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3459 - val_loss: 8.3507\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3461 - val_loss: 8.3449\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3438 - val_loss: 8.3389\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3475 - val_loss: 8.3393\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3446 - val_loss: 8.3582\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3490 - val_loss: 8.3388\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3476 - val_loss: 8.3392\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3480 - val_loss: 8.3743\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3463 - val_loss: 8.3397\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3449 - val_loss: 8.4014\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3478 - val_loss: 8.3918\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3476 - val_loss: 8.3389\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3498 - val_loss: 8.3388\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3464 - val_loss: 8.3403\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3489 - val_loss: 8.3393\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3473 - val_loss: 8.3398\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3474 - val_loss: 8.3459\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3440 - val_loss: 8.3388\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3474 - val_loss: 8.3552\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3470 - val_loss: 8.3389\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3451 - val_loss: 8.3778\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3460 - val_loss: 8.3389\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 8.3468 - val_loss: 8.3732\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "history_ker_reg.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_neurons': 40, 'n_hidden': 60, 'learning_rate': 0.001}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "history_ker_reg"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001C177B56610>,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.002, 0.003],\n",
       "                                        'n_hidden': range(10, 150, 10),\n",
       "                                        'n_neurons': range(20, 300, 20)},\n",
       "                   random_state=42, return_train_score=True)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Prediction of Unknown Data (Test Data)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Peparing Test Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X_test_prep = pipeline.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "X_test_prep"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Competition File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['ImageId','Label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction of Testdata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(\"Propability of all lables for given pixels: \", history_ker_reg.predict(X_test_prep[1].reshape(1,-1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Propability of all lables for given pixels:  [4.2738686 4.2702904 4.2769136 4.2693253 4.2672048 4.269359  4.2692513\n",
      " 4.2708354 4.27555   4.268281 ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print(\"Predicted Digit: \",np.argmax(history_ker_reg.predict(X_test_prep[1].reshape(1,-1))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted Digit:  2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "i = 1\r\n",
    "for row in X_test_prep:\r\n",
    "    index = i\r\n",
    "    predicted_label = np.argmax(history_ker_reg.predict(row.reshape(1,-1)))\r\n",
    "\r\n",
    "    mnist_competition_file = mnist_competition_file.append({'ImageId': index, 'Label': predicted_label}, ignore_index = True )\r\n",
    "    i = i + 1\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "mnist_competition_file"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      ImageId Label\n",
       "0           1     2\n",
       "1           2     2\n",
       "2           3     2\n",
       "3           4     2\n",
       "4           5     2\n",
       "...       ...   ...\n",
       "27995   27996     2\n",
       "27996   27997     2\n",
       "27997   27998     2\n",
       "27998   27999     2\n",
       "27999   28000     2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows  2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "mnist_competition_file.ImageId = mnist_competition_file.ImageId.astype(int)\r\n",
    "mnist_competition_file.Label = mnist_competition_file.Label.astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "mnist_competition_file.to_csv('mnist_submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b49f70aa2f17b03439dc8f4bbaf601f728142d0d0d774f4bbd10ea7a16b86ea"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('wingpuflake_keras': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}